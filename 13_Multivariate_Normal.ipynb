{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNelUAgfu/p9/gDgNgp6Jf2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Fitting a Multivariate Normal Distribution and Developing a Drought Index from it"],"metadata":{"id":"wFdQVSxy4z2i"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"2KsxscA_0Hl1"},"outputs":[],"source":["!pip install pyncei\n","!pip install lmoments3"]},{"cell_type":"markdown","source":["This notebook shows how to develop a summer drought index for Charlottesville based on its mean monthly summer precipitation and temperature. We'll use the pyncei package to get the climate data from NOAA (https://github.com/adamancer/pyncei). To illustrate spatial correlation, we'll download the data for Richmond as well.\n","\n","## Data Collection\n","To download the NOAA climate data, you'll need to get your own token here: https://www.ncdc.noaa.gov/cdo-web/token. Replace my token below with your own."],"metadata":{"id":"AcpkHCR95HYx"}},{"cell_type":"code","source":["from pyncei import NCEIBot, NCEIResponse\n","#ncei = NCEIBot(\"ExampleNCEIAPIToken\")\n","ncei = NCEIBot(\"klhIxphHLKDrrnjPtJGNpfEnfbERfUvZ\")"],"metadata":{"id":"csLYPNdP3NYM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Download monthly precipitation and temperature at Charlottesville and Richmond over overlapping period of record.\n","\n","Charlottesville: https://www.ncdc.noaa.gov/cdo-web/datasets/GSOM/stations/GHCND:USW00093736/detail  \n","Richmond: https://www.ncdc.noaa.gov/cdo-web/datasets/GSOM/stations/GHCND:USW00013740/detail"],"metadata":{"id":"ZVUWDeo56fzm"}},{"cell_type":"code","source":["# loop through each year and append to data frame because you can't download more than 1 year at a time\n","cville_df = NCEIResponse()\n","for year in range(1961,2024):\n","  cville_df.extend(\n","      ncei.get_data(\n","      datasetid=\"GSOM\",\n","      stationid=[\"GHCND:USW00093736\"],\n","      datatypeid=[\"TAVG\", \"PRCP\"], # degrees Celsius, mm\n","      startdate=str(year) + \"-05-01\",\n","      enddate=str(year+1) + \"-12-31\",\n","  )\n",")\n","\n","cville_df = cville_df.to_dataframe()\n","cville_df.head()"],"metadata":{"id":"OrCqk6i9UeA-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Get average monthly summer precipitation and temperature (June, July, August). First, determine the month and year of each data point."],"metadata":{"id":"DggEYo2cU4Ow"}},{"cell_type":"code","source":["from datetime import datetime\n","\n","cville_df['date'] = [datetime.strftime(dt, \"%Y-%m-%d\") for dt in cville_df['date']]\n","cville_df['date'] = [datetime.strptime(dt, \"%Y-%m-%d\") for dt in cville_df['date']]\n","cville_df['Month'] = [cville_df['date'].iloc[i].month for i in range(len(cville_df.index))]\n","cville_df['Year'] = [cville_df['date'].iloc[i].year for i in range(len(cville_df.index))]\n","cville_df"],"metadata":{"id":"u2Q_R7eaU_gL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Next, find the monthly averages over the summer months."],"metadata":{"id":"VvFqiF1v68Hv"}},{"cell_type":"code","source":["cville_df = cville_df.loc[cville_df['Month'].isin([6,7,8])]\n","cville_summer = cville_df.groupby(['Year','datatype'])['value'].mean().reset_index()\n","cville_summer"],"metadata":{"id":"1O7zeh9nXdxj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now repeat this process for the Richmond data."],"metadata":{"id":"o7mWzEhh7IsG"}},{"cell_type":"code","source":["# loop through each year and append to data frame because you can't download more than 1 year at a time\n","richmond_df = NCEIResponse()\n","for year in range(1961,2024):\n","  richmond_df.extend(\n","      ncei.get_data(\n","      datasetid=\"GSOM\",\n","      stationid=[\"GHCND:USW00013740\"],\n","      datatypeid=[\"TAVG\",\"PRCP\"], # degrees Celsius, mm\n","      startdate=str(year) + \"-05-01\",\n","      enddate=str(year+1) + \"-12-31\",\n","  )\n",")\n","\n","# convert data to dataframe and find month and year of each data point\n","richmond_df = richmond_df.to_dataframe()\n","richmond_df['date'] = [datetime.strftime(dt, \"%Y-%m-%d\") for dt in richmond_df['date']]\n","richmond_df['date'] = [datetime.strptime(dt, \"%Y-%m-%d\") for dt in richmond_df['date']]\n","richmond_df['Month'] = [richmond_df['date'].iloc[i].month for i in range(len(richmond_df.index))]\n","richmond_df['Year'] = [richmond_df['date'].iloc[i].year for i in range(len(richmond_df.index))]\n","\n","# compute average monthly precipitation and temperature over summer months\n","richmond_df = richmond_df.loc[richmond_df['Month'].isin([6,7,8])]\n","richmond_summer = richmond_df.groupby(['Year','datatype'])['value'].mean().reset_index()\n","richmond_summer"],"metadata":{"id":"rTDfAg_x7SVs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Combine data from Charlottesville and Richmond into a single data frame."],"metadata":{"id":"WASzTzWa7cn4"}},{"cell_type":"code","source":["import pandas as pd\n","\n","cville_summer = cville_summer.pivot(index='Year', columns='datatype', values='value')\n","richmond_summer = richmond_summer.pivot(index='Year', columns='datatype', values='value')\n","cville_summer.columns = ['PRCP_cville', 'TAVG_cville']\n","richmond_summer.columns = ['PRCP_richmond', 'TAVG_richmond']\n","climate_df = pd.concat([cville_summer, richmond_summer], axis=1)\n","climate_df"],"metadata":{"id":"Zawvn5UJCqRX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Remove NaN data points."],"metadata":{"id":"bD9K0x-W7i24"}},{"cell_type":"code","source":["climate_df = climate_df.dropna()\n","climate_df"],"metadata":{"id":"e_3dj1iut68J"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Data Visualization\n","\n","See how the data variables are correlated."],"metadata":{"id":"FZGu-wff7lnP"}},{"cell_type":"code","source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","corr_matrix = climate_df.corr()\n","\n","# Plot the correlation matrix using seaborn\n","sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n","plt.title('Correlation Matrix')\n","plt.show()"],"metadata":{"id":"6d2UhNdGGBGq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Temperature in Richmond is positively correlated with temperature in Charlottesville ($\\rho=0.69$). The same is true for precipitation at each location ($\\rho=0.6$). However, at each location, temperature and precipitation are negatively correlated with each other ($\\rho=-0.22$ in Charlottesville and $\\rho=-0.26$ in Richmond). So drier summers are also hotter, exacerbating drought conditions.\n","\n","## Fitting Multivariate Normal Distributions\n","\n","### Ensuring Marginal Distributions are Normal\n","\n","Let's create a multivariate drought index for Charlottesville incorporating both of these variables. We can do this by fitting a multivariate normal distribution to the two variables and using their inverse CDF to map their joint probability to an index. To fit a MVN, the marginal distributions of each variable have to be normal. Let's investigate that."],"metadata":{"id":"jJU-JMZ474Zu"}},{"cell_type":"code","source":["sns.pairplot(climate_df[[\"PRCP_cville\",\"TAVG_cville\"]], kind='reg', diag_kind='kde')\n","plt.show()"],"metadata":{"id":"PdWGWvKuDayt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Load code for fitting a normal distribution and testing the fit with a PPCC test."],"metadata":{"id":"g24hu8Y59H2C"}},{"cell_type":"code","source":["from google.colab import drive\n","\n","# allow access to google drive\n","drive.mount('/content/drive')\n","\n","!cp \"drive/MyDrive/Colab Notebooks/CE6280/CodingExamples/utils.py\" .\n","from utils import *"],"metadata":{"id":"TyzchVq8swMl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import scipy.stats as ss\n","import matplotlib.pyplot as plt\n","from lmoments3 import distr\n","import numpy as np\n","\n","class Normal(Distribution):\n","  def __init__(self):\n","    super().__init__()\n","    self.mu = None\n","    self.sigma = None\n","\n","  def fit(self, data, method):\n","    assert method == 'MLE' or method == 'MOM' or method == 'Lmom',\"method must = 'MLE', 'MOM' or 'Lmom'\"\n","\n","    self.findMoments(data)\n","    if method == 'MLE':\n","      self.mu, self.sigma = ss.norm.fit(data)\n","    elif method == 'MOM':\n","      self.mu = self.xbar\n","      self.sigma = np.sqrt(self.var)\n","    elif method == 'Lmom':\n","      norm_params = distr.nor.lmom_fit(data)\n","      self.mu = norm_params[\"loc\"]\n","      self.sigma = norm_params[\"scale\"]\n","\n","  def findReturnPd(self, T):\n","    q_T = ss.norm.ppf(1-1/T, self.mu, self.sigma)\n","    return q_T\n","\n","  def plotHistPDF(self, data, min, max, title):\n","    x = np.arange(min, max,(max-min)/100)\n","    f_x = ss.lognorm.pdf(x, self.mu, self.sigma)\n","    self.plotDistFit(data, x, f_x, min, max, title)\n","\n","  def ppccTest(self, data, title, m=10000):\n","    # calculate test statistic, rho\n","    x_sorted = np.sort(data)\n","    p_observed = ss.mstats.plotting_positions(x_sorted)\n","    x_fitted = ss.norm.ppf(p_observed, self.mu, self.sigma)\n","    self.ppcc_rho = np.corrcoef(x_sorted, x_fitted)[0,1]\n","\n","    # generate m synthetic samples of n observations to estimate null distribution of rho\n","    rhoVector = np.zeros(m)\n","    for i in range(m):\n","      np.random.seed(i)\n","      x = ss.norm.rvs(self.mu, self.sigma, size=len(data))\n","      rhoVector[i] = np.corrcoef(np.sort(x), x_fitted)[0,1]\n","\n","    # calculate p-value of test and make QQ plot\n","    count = 0\n","    for i in range(len(rhoVector)):\n","      if self.ppcc_rho < rhoVector[i]:\n","        count = count + 1\n","\n","    self.p_value_PPCC = 1 - count/(len(rhoVector) + 1)\n","\n","    # make Q-Q plot\n","    plt.scatter(x_sorted,x_fitted,color='b')\n","    plt.plot(x_sorted,x_sorted,color='r')\n","    plt.xlabel('Observations')\n","    plt.ylabel('Fitted Values')\n","    plt.title(title)\n","    plt.show()\n","\n","  def calcCI(self, data, p, CI, method, npars, seed):\n","    n = len(data)\n","    alpha = (100.0-CI)/100.0\n","    # calculate theoretical confidence interval using formula from slides\n","    z_p = ss.norm.ppf(p)\n","    z_crit = ss.norm.ppf(1-alpha/2)\n","    x_p = self.mu + z_p*self.sigma\n","    LB = x_p - z_crit * np.sqrt(self.sigma**2 * (1+0.5*z_p**2)/n)\n","    UB = x_p + z_crit * np.sqrt(self.sigma**2 * (1+0.5*z_p**2)/n)\n","    return LB, UB"],"metadata":{"id":"LJVeg0WP82gI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Use a PPCC test to test for normality of precipitation."],"metadata":{"id":"QeW0XOCZ9Eum"}},{"cell_type":"code","source":["dist_precip = Normal()\n","dist_precip.fit(climate_df[\"PRCP_cville\"], \"MLE\")\n","dist_precip.ppccTest(climate_df[\"PRCP_cville\"], \"Normal Fit\")\n","dist_precip.p_value_PPCC"],"metadata":{"id":"q0qKv6S-tkgo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We do not reject that the precipitation data is normal, so we do not need to transform it. Let's repeat with the temperature data."],"metadata":{"id":"80-W4kWu9MuA"}},{"cell_type":"code","source":["dist_temp = Normal()\n","dist_temp.fit(climate_df[\"TAVG_cville\"], \"MLE\")\n","dist_temp.ppccTest(climate_df[\"TAVG_cville\"], \"Normal Fit\")\n","dist_temp.p_value_PPCC"],"metadata":{"id":"letTV_QMuNrk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Once again, we do not reject that the temperature data is normal, so we do not need to transform it.\n","\n","### Ensuring the Mahalanobis distance has a $\\chi^2$ distribution\n","\n","Below we write a class for the $\\chi^2$ distribution that initializes it with its single parameter (the number of degrees of freedom), and tests the goodness of fit with a PPCC test."],"metadata":{"id":"y1OOfu_s9Sq4"}},{"cell_type":"code","source":["class ChiSq(Distribution):\n","  def __init__(self):\n","    super().__init__()\n","    self.df = None\n","\n","  def ppccTest(self, data, title, m=10000):\n","    # calculate test statistic, rho\n","    x_sorted = np.sort(data)\n","    p_observed = ss.mstats.plotting_positions(x_sorted)\n","    x_fitted = ss.chi2.ppf(p_observed, self.df)\n","    self.ppcc_rho = np.corrcoef(x_sorted, x_fitted)[0,1]\n","\n","    # generate m synthetic samples of n observations to estimate null distribution of rho\n","    rhoVector = np.zeros(m)\n","    for i in range(m):\n","      np.random.seed(i)\n","      x = ss.chi2.rvs(self.df, size=len(data))\n","      rhoVector[i] = np.corrcoef(np.sort(x), x_fitted)[0,1]\n","\n","    # calculate p-value of test and make QQ plot\n","    count = 0\n","    for i in range(len(rhoVector)):\n","      if self.ppcc_rho < rhoVector[i]:\n","        count = count + 1\n","\n","    self.p_value_PPCC = 1 - count/(len(rhoVector) + 1)\n","\n","    # make Q-Q plot\n","    plt.scatter(x_sorted,x_fitted,color='b')\n","    plt.plot(x_sorted,x_sorted,color='r')\n","    plt.xlabel('Observations')\n","    plt.ylabel('Fitted Values')\n","    plt.title(title)\n","    plt.show()"],"metadata":{"id":"7AIhovEjwYDE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can compute the Mahalanobis distances of all observations from the mean using the function [scipy.spatial.distance.mahalanobis](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.mahalanobis.html), which takes in three arguments: the coordinates of the two points between whose distance is being calculated (the observations and the mean), and the inverse of the covariance matrix between the variables."],"metadata":{"id":"TuEghV899vfq"}},{"cell_type":"code","source":["from scipy.spatial import distance\n","\n","mu = np.mean(climate_df[[\"PRCP_cville\",\"TAVG_cville\"]],axis=0)\n","print(\"Mean vector: \\n\", mu)\n","cov = np.cov(climate_df[[\"PRCP_cville\",\"TAVG_cville\"]].T)\n","print(\"Covariance matrix: \\n\", cov)\n","\n","dists = np.zeros(len(climate_df.index))\n","\n","for i in range(len(dists)):\n","  dists[i] = distance.mahalanobis(climate_df[[\"PRCP_cville\",\"TAVG_cville\"]].iloc[i], mu, np.linalg.inv(cov))\n","\n","dists_chi2fit = ChiSq()\n","dists_chi2fit.df = 2 # number of variables\n","dists_chi2fit.ppccTest(dists**2, \"Chi-Squared Fit\")\n","dists_chi2fit.p_value_PPCC"],"metadata":{"id":"nBahldzTubDE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We do not reject that the Mahalanobis distances come from a $\\chi^2$ distibution with 2 degrees of freedom (for the 2 variables: average monthly summer precipitation and temperature in Charlottesville). This suggests the MVN distribution is appropriate.\n","\n","## Visualizing the MVN Distribution\n","\n","We can create an object of the [scipy.stats.multivariate_normal](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.multivariate_normal.html) class and compute its pdf to visualize the joint probability over a grid of possible precipitation and temperature values. We plot this on a contour map below using [matplotlib.pyplot.contourf](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.contourf.html)."],"metadata":{"id":"dycqFttk-eFL"}},{"cell_type":"code","source":["x, y = np.mgrid[0:200:2, 21:27:0.06]\n","pos = np.empty(x.shape + (2,))\n","pos[:, :, 0] = x\n","pos[:, :, 1] = y\n","rv = ss.multivariate_normal(mu, cov)\n","\n","colors = plt.contourf(x, y, rv.pdf(pos))\n","plt.scatter(climate_df['PRCP_cville'], climate_df['TAVG_cville'],c='k')\n","cbar = plt.colorbar(colors)\n","cbar.set_label('Probability Density')\n","plt.xlabel('Avg Monthly Summer Precip (mm)')\n","plt.ylabel('Avg Monthly Summer Temp (C)')\n","plt.title('Multivariate Normal Distribution')\n","plt.show()"],"metadata":{"id":"ZpaZWojVxm-s"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can also visualize this in three dimensions using [mpl_toolkits.mplot3d.Axes3D](https://matplotlib.org/3.5.1/api/_as_gen/mpl_toolkits.mplot3d.axes3d.Axes3D.html)."],"metadata":{"id":"1kxZ9nt9_Uq8"}},{"cell_type":"code","source":["from mpl_toolkits.mplot3d import Axes3D\n","from matplotlib import cm\n","\n","fig = plt.figure()\n","ax = fig.add_subplot(projection='3d')\n","surf = ax.plot_surface(x,y,rv.pdf(pos),cmap=cm.coolwarm,linewidth=0,antialiased=False)\n","ax.set_xlabel('Avg Monthly Summer Precip (mm)')\n","ax.set_ylabel('Avg Monthly Summer Temp (C)')\n","ax.set_zlabel('Probability Density')\n","fig.tight_layout()\n","fig.show()"],"metadata":{"id":"F094kfzuyPtP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Conditional Distributions\n","\n","Given the correlation between these variables, we can use the joint distribution to compute the conditional distribution of one variable given a particular value of another. Let's compute the conditional distribution of average summer monthly temperature given average summer monthly precipitation of 40 mm."],"metadata":{"id":"h8R_gspT_iUw"}},{"cell_type":"code","source":["# find conditional distribution of temperature given precipitation is 40\n","mu_cond = mu[1] + cov[1,0]*(1/cov[0,0])*(40-mu[0])\n","cov_cond = cov[1,1] - cov[1,0]*(1/cov[0,0])*cov[0,1]\n","\n","# plot marginal vs. conditional temperature distribution\n","x = np.arange(np.min(climate_df['TAVG_cville']),np.max(climate_df['TAVG_cville']),\\\n","              (np.max(climate_df['TAVG_cville'])-np.min(climate_df['TAVG_cville']))/100)\n","plt.plot(x,ss.norm.pdf(x,mu[1],np.sqrt(cov[1,1])),c='b',label=\"Unconditional Temp Dist\")\n","plt.plot(x,ss.norm.pdf(x,mu_cond,np.sqrt(cov_cond)),c='g',label=\"Temp Dist Given P=40 mm\")\n","plt.legend()\n","plt.xlabel('Avg Monthly Summer Temp (C)')\n","plt.ylabel('Probability Density')\n","plt.show()"],"metadata":{"id":"i2T_Wnv_zxKx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Developing Drought Indices\n","\n","It is common to use the CDF of a distribution to create a drought index by mapping the cumulative probability to the corresponding z-score of a standard normal distribution. We can do this using the CDF of a univariate or multivariate distribution.\n","\n","Below we plot the CDF of the joint distribution between temperature and precipitation from our MVN fit. Note, we have negated the temperature so that low values of each correspond to drought conditions. This is because the CDF is the probability both variables are below particular values, so a drought index based on that should have both variables (or all variables if >2) arranged such that low values of each (all) correlate with stronger drought conditions."],"metadata":{"id":"zbdtTlE8_5eF"}},{"cell_type":"code","source":["# plot cumulative probabilities contours\n","# negate temperature so that low values of both are bad and high values of both are good\n","# we will use this to create a drought index where low cumulative probabilities are low\n","# and high cumulative probabilities are high\n","climate_df['TAVG_cville'] = -climate_df['TAVG_cville']\n","mu = np.mean(climate_df[[\"PRCP_cville\",\"TAVG_cville\"]],axis=0)\n","cov = np.cov(climate_df[[\"PRCP_cville\",\"TAVG_cville\"]].T)\n","rv = ss.multivariate_normal(mu, cov)\n","\n","x, y = np.mgrid[0:200:2, 21:27:0.06]\n","pos[:, :, 0] = x\n","pos[:, :, 1] = -y\n","colors = plt.contourf(x,-y,rv.cdf(pos))\n","plt.scatter(climate_df['PRCP_cville'],climate_df['TAVG_cville'],c='k')\n","plt.colorbar(colors)"],"metadata":{"id":"_19kIt06zyDq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now we use the above joint CDF, as well as the marginal CDFs for comparison, to develop drought indices for Charlottesville. For each year, we compute the percentile of the observed precipitation and temperature alone and together using the CDF. We then map that percentile to the corresponding z-score of a standard normal distributionb using its inverse CDF (point percentile function in scipy.stats)."],"metadata":{"id":"kS5WawVZA7hX"}},{"cell_type":"code","source":["# find cumulative probability for each observation\n","# convert that to a drought index by finding its corresponding z-score of the standard normal\n","cumProbs = np.zeros(len(climate_df['TAVG_cville']))\n","MVdroughtIndices = np.zeros(len(climate_df['TAVG_cville']))\n","for i in range(len(cumProbs)):\n","    cumProbs[i] = rv.cdf([climate_df['PRCP_cville'].iloc[i],climate_df['TAVG_cville'].iloc[i]])\n","    MVdroughtIndices[i] = ss.norm.ppf(cumProbs[i])\n","\n","# find drought indices with just temperature or precipitation\n","rv_x = ss.norm(mu[0],np.sqrt(cov[0,0]))\n","rv_y = ss.norm(mu[1],np.sqrt(cov[1,1]))\n","tempDroughtIndices = np.zeros(len(MVdroughtIndices))\n","precipDroughtIndices = np.zeros(len(MVdroughtIndices))\n","for i in range(len(tempDroughtIndices)):\n","    precipDroughtIndices[i] = ss.norm.ppf(rv_x.cdf(climate_df['PRCP_cville'].iloc[i]))\n","    tempDroughtIndices[i] = ss.norm.ppf(rv_y.cdf(climate_df['TAVG_cville'].iloc[i]))\n","\n","# compare them\n","plt.plot(climate_df.index,MVdroughtIndices,c='g',label=\"Multivariate Drought Index\")\n","plt.plot(climate_df.index,tempDroughtIndices,c='r',label=\"Temperature Drought Index\")\n","plt.plot(climate_df.index,precipDroughtIndices,c='b',label=\"Precipitation Drought Index\")\n","plt.plot(climate_df.index,np.zeros(len(climate_df.index)),c='k',linestyle='--')\n","plt.legend()\n","plt.xlabel('Year')\n","plt.ylabel('Drought Index')\n","plt.show()"],"metadata":{"id":"QwW0XEiCz1D8"},"execution_count":null,"outputs":[]}]}