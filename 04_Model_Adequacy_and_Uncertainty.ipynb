{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNvfhN/emUqp9xOWFuO5cKf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Goodness of Fit Tests for Model Adequacy and Quantifying Uncertainty"],"metadata":{"id":"YFXC5qT8eBOq"}},{"cell_type":"code","source":["!pip install lmoments3"],"metadata":{"id":"QdwuFupBFRBi"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QtFNkDuIYwA8"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import scipy.stats as ss\n","import matplotlib.pyplot as plt\n","from google.colab import drive\n","\n","# allow access to google drive\n","drive.mount('/content/drive')\n","\n","!cp \"drive/MyDrive/Colab Notebooks/CE6280/CodingExamples/utils.py\" .\n","from utils import *\n","\n","maxQ = pd.read_csv(\"drive/MyDrive/Colab Notebooks/CE6280/Data/Problem6.17.csv\")"]},{"cell_type":"markdown","source":["## Goodness of Fit Tests"],"metadata":{"id":"Dsz33XL4Xp3l"}},{"cell_type":"markdown","source":["### Test for Non-zero Skewness\n","First, to determine if we should fit a skewed distribution or not, we should test if the skewness of the data is different than 0. The test statistic, $z$, for this test is the following, which should have a standard normal distribution:  \n","$$z = \\frac{\\hat{\\gamma}}{\\sqrt{\\frac{6(n-2)}{(n+1)(n+3)}}}$$  \n","where $\\hat{\\gamma}$ is the sample skewness coefficient."],"metadata":{"id":"lFz9U2N2CT26"}},{"cell_type":"code","source":["def skewtest(data):\n","  g = ss.skew(data,bias=False)\n","  print(\"Sample skewness: %0.2f\" % g)\n","  n = len(data)\n","  z = g / np.sqrt(6*(n-2) / ((n+1)*(n+3)))\n","  if z > 0:\n","    p_one_sided = 1 - ss.norm.cdf(z)\n","  else:\n","    p_one_sided = ss.norm.cdf(z)\n","\n","  p_two_sided = 2*p_one_sided\n","\n","  return p_one_sided, p_two_sided\n","\n","p_one_sided, p_two_sided = skewtest(maxQ[\"Flow\"])\n","\n","print(\"One-sided p-value: %.2e\" % p_one_sided)\n","print(\"Two-sided p-value: %.2e\" % p_two_sided)"],"metadata":{"id":"Km6CUWsSd9zJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Whether one or two sided (one-sided is probably appropriate for untransformed flood data), we absolutely reject the data has 0 skew!  \n","\n","What about the log-transformed data?"],"metadata":{"id":"8POgpA4YCXNz"}},{"cell_type":"code","source":["p_one_sided, p_two_sided = skewtest(np.log(maxQ[\"Flow\"]))\n","\n","print(\"One-sided p-value: %.2e\" % p_one_sided)\n","print(\"Two-sided p-value: %.2e\" % p_two_sided)"],"metadata":{"id":"FxysAHzzCh8B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["For this we should probably use a 2-sided test, but even then, the log-transformed data has significantly positive skew. This suggests even the log of the data is not normal, so a log-normal distribution still may not sufficiently fit our data.  \n","\n","### Test for distribution fit with Kolmogorov-Smirnov (K-S) Test\n","\n","Let's test the fit of the LN2 and LN3 distributions using MOM, MLE and Lmom statistically with a K-S test. The test statistic for this test is $D$, the maximum distance between the fitted and empirical distributions:  \n","$$\\require{amsmath}  \n","D = \\text{sign} \\underset{x}{\\max} |F_{empirical}(x) - F_{fitted}(x)| $$"],"metadata":{"id":"WvgDUVKFDOwb"}},{"cell_type":"code","source":["methods = [\"MOM\", \"MLE\", \"Lmom\"]\n","npars = [2, 3]\n","p = ss.mstats.plotting_positions(maxQ[\"Flow\"])\n","p = np.sort(p)\n","\n","for method in methods:\n","  for npar in npars:\n","    LN = LogNormal()\n","    LN.fit(maxQ[\"Flow\"], method, npar)\n","    result = ss.kstest(maxQ[\"Flow\"], ss.lognorm.ppf(p, s=LN.sigma, loc=LN.tau, scale=np.exp(LN.mu)), alternative='two-sided')\n","    print(\"p-value of 2-sided K-S test for LN%d %s fit: %f\" % (npar, method, result.pvalue))"],"metadata":{"id":"WHd83crDDozm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["According to the K-S test, we cannot reject that the data came from any of these distributions, but we are most confident in the LN3 MLE and LN3 Lmom fits and least confident in the MOM fits for LN2 and LN3.  \n","\n","### Test for distribution fit with Probability Plot Correlation Coefficient (PPCC) Test\n","\n","The PPCC test is more powerful though, meaning it is less likely to accept the null hypothesis when the data doesn't actually come from that distribution. What does the Probability Plot Correlation Coefficient (PPCC) test conclude for each fit?\n","\n","There is a Python function for finding the PPCC under different shape parameters of a distribution: [ppcc_plot](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ppcc_plot.html). This also reports the shape parameter that results in the greatest PPCC. But it does not perform a Monte Carlo-based hypothesis test to estimate the probability your data could have come from that distribution. So we will have to write our own code for that."],"metadata":{"id":"E-9Si-lVJM0S"}},{"cell_type":"code","source":["def ppccTest(data, fitted_dist, distname, title, m=10000):\n","  x_sorted = np.sort(data)\n","  p_observed = ss.mstats.plotting_positions(x_sorted)\n","  if distname == 'LN': # you'll add elif statements for alternative distributions for your next homework\n","    # get fitted quantiles\n","    x_fitted = ss.lognorm.ppf(p_observed, s=fitted_dist.sigma, loc=fitted_dist.tau, scale=np.exp(fitted_dist.mu))\n","\n","    # generate m synthetic samples of n observations\n","    rhoVector = np.zeros(m)\n","    for i in range(m):\n","      np.random.seed(i)\n","      x = ss.lognorm.rvs(s=fitted_dist.sigma, loc=fitted_dist.tau, scale=np.exp(fitted_dist.mu), size=len(data))\n","      rhoVector[i] = np.corrcoef(np.sort(x), x_fitted)[0,1]\n","\n","  # calculate test statistic\n","  rho = np.corrcoef(x_sorted, x_fitted)[0,1]\n","\n","  # calculate pvalue of test statistic from Monte Carlo simulation\n","  count = 0\n","  for i in range(len(rhoVector)):\n","    if rho < rhoVector[i]:\n","      count = count + 1\n","\n","  p_value = 1 - count/(m+1)\n","\n","  # make Q-Q plot\n","  plt.scatter(x_sorted,x_fitted,color='b')\n","  plt.plot(x_sorted,x_sorted,color='r')\n","  plt.xlabel('Observations')\n","  plt.ylabel('Fitted Values')\n","  plt.title(title)\n","  plt.show()\n","\n","  return rho, p_value\n","\n","for method in methods:\n","  for npar in npars:\n","    LN = LogNormal()\n","    LN.fit(maxQ[\"Flow\"], method, npar)\n","    rho, p_value = ppccTest(maxQ[\"Flow\"], LN, 'LN', 'QQ plot for LN' + str(npar) + ' fit with ' + method)\n","    print(\"p-value of PPCC test for LN%d %s fit: %f\" % (npar, method, p_value))"],"metadata":{"id":"ucg8-jb1JpvZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["You can see the p-values are much lower for these tests, so we're closer to rejecting that the data came from these distributions. The best fit is LN3 Lmom, followed closely by LN3 MLE. But clearly the fits aren't great in the Q-Q plots, so it would be good to quantify uncertainty in quantile estimates from these fits like the 100-year flood.  \n","\n","# Quantifying Uncertainty in Quantile Estimates\n","\n","In the slides, we showed how to do this theoretically for the LN2 distribution, but not the LN3 distribution, so for that we'll use bootstrapping. You can add these functions to the LogNormal class in `utils.py` for the future, replacing `dist` with `self`, and write similar functions for the other distributions on your next homework.  \n","\n","For bootstrapping, we'll load a function from the `astropy` library, which we have to install first."],"metadata":{"id":"qoD1pIglQxEs"}},{"cell_type":"code","source":["!pip install astropy"],"metadata":{"id":"Py5dB1WMZOuE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The analytical confidence interval for the p-th quantile of the LN2 distribution, $x_p$ is:  \n","$$CI(x_p) = \\exp\\Bigg(x_p - z_{1-\\alpha/2} \\sqrt{\\frac{\\hat{\\sigma^2}}{n}\\big(1+0.5z_p^2\\big)}, x_p + z_{1-\\alpha/2} \\sqrt{\\frac{\\hat{\\sigma^2}}{n}\\big(1+0.5z_p^2\\big)} \\Bigg)$$  \n","where  \n","$$x_p = \\hat{\\mu} + z_p\\hat{\\sigma}$$  \n","and $\\hat{\\mu}$ and $\\hat{\\sigma}$ are the fitted parameters of the LN2 distribution."],"metadata":{"id":"FnkODRI7FLNY"}},{"cell_type":"code","source":["from astropy.stats import bootstrap as bootstrap\n","\n","def calcCI(dist, data, p, CI, method, npars, seed, m=1000):\n","  '''Function for finding `CI`% confidence interval of\n","  `p`-th percentile of distribution `dist`\n","  with `npars` parameters fit to `data` using `method`\n","  with random seed `seed` if bootstrapping'''\n","  n = len(data)\n","  alpha = (100.0-CI)/100.0\n","  if npars == 2:\n","    # calculate theoretical confidence interval using formula from slides\n","    z_p = ss.norm.ppf(p)\n","    z_crit = ss.norm.ppf(1-alpha/2)\n","    x_p = dist.mu + z_p*dist.sigma\n","    LB = np.exp(x_p - z_crit * np.sqrt(dist.sigma**2 * (1+0.5*z_p**2)/n))\n","    UB = np.exp(x_p + z_crit * np.sqrt(dist.sigma**2 * (1+0.5*z_p**2)/n))\n","    return LB, UB\n","  elif npars == 3:\n","    # calculate confidence interval from m bootstrap samples\n","    np.random.seed(seed)\n","    sample = bootstrap(data, m)\n","    q_sample = np.zeros(m)-999 # initialize estimates at -999\n","    # estimate p-th percentile by fitting distribution to each bootstrap sample\n","    for i in range(m):\n","      LN = LogNormal()\n","      try:\n","        LN.fit(sample[i,:], method, npars)\n","        q_sample[i] = LN.findReturnPd(1/(1-p))\n","      except:\n","        pass\n","\n","    # sort bootstrap samples and find confidence interval from empirical quantiles of sampled estimates\n","    q_sample = np.sort(q_sample)\n","    keep_indices = np.intersect1d(np.where(~np.isnan(q_sample))[0],np.where(q_sample != -999)[0]) # remove failed fits\n","    q_sample = q_sample[keep_indices]\n","    LB = q_sample[int((alpha/2)*len(q_sample))]\n","    UB = q_sample[int((1-alpha/2)*len(q_sample))]\n","    return LB, UB, q_sample\n","\n","for method in methods:\n","  for npar in npars:\n","    LN = LogNormal()\n","    LN.fit(maxQ[\"Flow\"], method, npar)\n","    # calculate 95% confidence interval on 100-yr flood\n","    if npar == 2:\n","      LB, UB = calcCI(LN, maxQ[\"Flow\"], 0.99, 95, method, npar, 1923)\n","    elif npar == 3:\n","      LB, UB, q_sample = calcCI(LN, maxQ[\"Flow\"], 0.99, 95, method, npar, 1923)\n","\n","    print(\"95%% confidence interval for 100-yr flood estimate from LN%d %s fit: %f, %f\" % (npar, method, LB, UB))"],"metadata":{"id":"TyYGxEb2VPWZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This returned a crazy upper bound of the 95% CI for the LN3 MLE fit! This is an example of how the MLE fits can be unstable. This had initialized the estimates with Lmom. We scaling the data and then fitting the distribution."],"metadata":{"id":"8brwCtVKfJOT"}},{"cell_type":"code","source":["method = 'MLE'\n","npar = 3\n","LN = LogNormal()\n","z = (maxQ[\"Flow\"]-np.mean(maxQ[\"Flow\"])) / np.std(maxQ[\"Flow\"],ddof=1)\n","LN.fit(z, method, npar)\n","# calculate 95% confidence interval on 100-yr flood\n","LB, UB, q_sample = calcCI(LN, maxQ[\"Flow\"], 0.99, 95, method, npar, 1923)\n","LB = LB*np.std(maxQ[\"Flow\"],ddof=1) + np.mean(maxQ[\"Flow\"])\n","UB = UB*np.std(maxQ[\"Flow\"],ddof=1) + np.mean(maxQ[\"Flow\"])\n","print(\"95%% confidence interval for 100-yr flood estimate from LN%d %s fit: %f, %f\" % (npar, method, LB, UB))\n","print(\"All sorted bootstrapped estimates of 100-yr flood:\")"],"metadata":{"id":"bFQhhA8BxSzj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We still got a crazy upper bound, but we also got an error in finding the log of the data minus the lower bound, so clearly there were some problematic parameter estimates.  \n","\n","Let's look at all of the 100-year flood estimates."],"metadata":{"id":"PyYZf_YS7uRR"}},{"cell_type":"code","source":["print(q_sample)"],"metadata":{"id":"Jxc3l_92ABz-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["There is a jump from estimates being on the order of E4 to E9! How often does this happen?\n"],"metadata":{"id":"dGtmlnPzAEXy"}},{"cell_type":"code","source":["len(np.where(q_sample>1E5)[0])/len(q_sample)"],"metadata":{"id":"hkCEwvFpARMF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This happens in about 15% of the bootstrapped samples, so it's not only a few cases. In this case, we probably just shouldn't consider using the uncertainty in the LN3 estimates for flood design!"],"metadata":{"id":"B0GkFhrMAXM_"}}]}