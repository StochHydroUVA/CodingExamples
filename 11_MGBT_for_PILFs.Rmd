{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOTTWvyN+viupKyjAZfEntr"},"kernelspec":{"name":"ir","display_name":"R"},"language_info":{"name":"R"}},"cells":[{"cell_type":"markdown","source":["# Multiple Grubbs Beck Test (MGBT) for Potentially Influential Low Flows (PILFs)\n","\n","This notebook uses the [MGBT library](https://code.usgs.gov/water/stats/MGBT) in R to find and remove PILFs from annual maxima series using the MGBT."],"metadata":{"id":"kAH3WPqQ_Su9"}},{"cell_type":"code","source":["install.packages(\"MGBT\")\n","packageurl=\"https://cran.r-project.org/src/contrib/Archive/fitdistrplus/fitdistrplus_1.1-11.tar.gz\"\n","install.packages(packageurl, repos=NULL, type=\"source\")\n","install.packages(\"e1071\")\n","install.packages(\"ppcc\")\n","install.packages(\"FAdist\")\n","install.packages(\"tidyverse\")\n","install.packages(\"ggplot2\")\n","install.packages(\"scales\")"],"metadata":{"id":"6juIm9k__oor"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now click the folder to the left and drag $\\texttt{Santa_Cruz_Creek_CA.csv}$ to $\\texttt{sample_data}$ to upload it."],"metadata":{"id":"KrKjvz90Eyi2"}},{"cell_type":"code","source":["data <- read.csv('sample_data/Santa_Cruz_Creek_CA.csv')\n","head(data)\n","print(dim(data))"],"metadata":{"id":"iGO5A2TZDWcn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["There are some NA values in the data that we need to remove."],"metadata":{"id":"Qr00rY9tMwul"}},{"cell_type":"code","source":["library(tidyverse)\n","data = drop_na(data)\n","dim(data)"],"metadata":{"id":"QgxxbNzZKqSk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's fit an LP3 distribution to the 1-Day Annual Maxima without removing any outliers and investigate the fit. We'll also use it to estimate the 100-yr and 500-yr flods. The code below contains necessary functions for fitting a P3 distribution using method of moments."],"metadata":{"id":"mg5tHkSxHYNI"}},{"cell_type":"code","source":["library(e1071)\n","library(ppcc)\n","library(FAdist)\n","\n","# function to calculate central empirical moments\n","memp.centered  =  function(x, order){\n","  if(order == 1){\n","    return (mean(x))\n","  } else if(order == 2){\n","    return (var(x))\n","  } else if(order == 3){\n","    return (e1071::skewness(x, type=2))\n","  }\n","}\n","\n","# function to calculate parameters of P3 distribution using MOM\n","gamma3MOM = function(data){\n","  alpha = 4/(e1071::skewness(data,type=2))^2\n","  beta = sqrt(alpha) / sd(data)\n","  xi = mean(data) - alpha/beta\n","  return(list(alpha=alpha, beta=beta, xi=xi))\n","}\n","\n","# function to calculate central theoretical moments of P3 distribution\n","mgamma3 = function(order, shape, scale, thres){\n","  xi = thres\n","  alpha = shape\n","  beta = 1/scale\n","  if(order == 1){\n","    return (xi + alpha/beta)\n","  } else if(order == 2){\n","    return ( alpha/beta^2 )\n","  } else if(order == 3){\n","    return ( 2/sqrt(alpha) )\n","  }\n","}\n","\n","# Expected Moments Algorithm\n","EMA_gamma3 = function(x, y, s, h, T, params0, tolerance, maxiter){\n","  # x = log-space systematic flows\n","  # y = log-space historical flows\n","  # s = length of systematic record\n","  # h = length of historical record\n","  # T = log-space threshold\n","  # tolerance for convergence (total % difference in 3 parameter estimates)\n","  # maxiter = maximum number of iterations if convergence tolerance never met\n","\n","  # create a vector (y_prime) of all of the floods above the threshold (T)\n","  # in both the historical (y) and systematic (x) records\n","  y_prime = c(y[which(y>=T)], x[which(x>=T)])\n","  k = length(y[which(y>=T)]) # number of historical floods over the threshold\n","\n","  # get a vector of all observed peaks below the threshold (those during the systematic record)\n","  x_prime = x[which(x<T)]\n","  m = s - length(x_prime) # number of peaks in systematic record that exceeded T\n","\n","  # Step 1: estimate parameters alpha_hat, beta_hat, xi_hat with MOM using only systematic record\n","  alpha_hat = params0$alpha\n","  beta_hat = params0$beta\n","  xi_hat = params0$xi\n","\n","  # Step 2: update estimate of sample moments\n","  # calculate constants c2 and c3\n","  c2 = (s+k) / (s+k-1)\n","  c3 = (s+k)^2 / ((s+k-1)*(s+k-2))\n","  # iterate till convergence or max number of iterations\n","  for(i in 1:maxiter){\n","    if(beta_hat>0){\n","      # find expected value below the threshold with current parameter estimates\n","      exp_gamma = function(x) (x*dgamma3(x, alpha_hat, 1/beta_hat, xi_hat))\n","      integral = integrate(exp_gamma, lower=-Inf, upper=T, subdivisions=10000)\n","      E_xH_below = integral[[1]] / (pgamma3(T, alpha_hat, 1/beta_hat, xi_hat))\n","    } else {\n","      # find expected value above the -threshold with current parameter estimates\n","      # then negate back to get expected value below the threshold\n","      exp_gamma = function(x) (x*dgamma3(x, alpha_hat, -1/beta_hat, xi_hat))\n","      integral = integrate(exp_gamma, lower=-T, upper=Inf, subdivisions=10000)\n","      E_xH_below = -integral[[1]] / (1-pgamma3(-T, alpha_hat, -1/beta_hat, xi_hat))\n","    }\n","\n","    # update estimate of mean\n","    mu_new = (sum(x_prime) + sum(y_prime) + (h-k)*E_xH_below) / (s+h)\n","\n","    # find expected value of x^2 below the threshold with latest parameter estimates\n","    if(beta_hat>0){\n","      exp2_gamma = function(x) ((x-mu_new)^2 *\n","                               dgamma3(x, alpha_hat, 1/beta_hat, xi_hat))\n","      integral2 = integrate(exp2_gamma, lower=-Inf, upper=T, subdivisions=10000)\n","      E_x2H_below = integral2[[1]] / (pgamma3(T, alpha_hat, 1/beta_hat, xi_hat))\n","    } else {\n","      exp2_gamma = function(x) ((x+mu_new)^2 *\n","                               dgamma3(x, alpha_hat, -1/beta_hat, xi_hat))\n","      integral2 = integrate(exp2_gamma, lower=-T, upper=Inf, subdivisions=10000)\n","      E_x2H_below = integral2[[1]] / (1-pgamma3(-T, alpha_hat, -1/beta_hat, xi_hat))\n","    }\n","\n","    # update estimate of standard deviation\n","    sigma_new = sqrt((c2*(sum((x_prime-mu_new)^2) + sum((y_prime-mu_new)^2)) +\n","                       (h-k)*E_x2H_below) / (s+h))\n","\n","    # find expected value of x^3 below the threshold with latest parameter estimates\n","    if(beta_hat>0){\n","      exp3_gamma = function(x) ((x-mu_new)^3 *\n","                                dgamma3(x, alpha_hat, 1/beta_hat, xi_hat))\n","      integral3 = integrate(exp3_gamma, lower=-Inf, upper=T, subdivisions=10000)\n","      E_x3H_below = integral3[[1]] / (pgamma3(T, alpha_hat, 1/beta_hat, xi_hat))\n","    } else {\n","      exp3_gamma = function(x) ((x+mu_new)^3 *\n","                                dgamma3(x, alpha_hat, -1/beta_hat, xi_hat))\n","      integral3 = integrate(exp3_gamma, lower=-T, upper=Inf, subdivisions=10000)\n","      E_x3H_below = -integral3[[1]] / (1-pgamma3(-T, alpha_hat, -1/beta_hat, xi_hat))\n","    }\n","\n","    # update estimate of skewness\n","    gamma_new = ((c3*(sum((x_prime-mu_new)^3) + sum((y_prime-mu_new)^3))\n","                  + (h-k)*E_x3H_below)) / ((s+h)*sigma_new^3)\n","\n","    # update estimates LP3 parameters\n","    alpha_new = 4/(gamma_new)^2\n","    beta_new = sqrt(alpha_new) / sigma_new\n","    xi_new = mu_new + alpha_new/beta_new\n","    if(gamma_new<0){\n","      beta_new = -beta_new\n","      xi_new = -xi_new\n","    }\n","\n","    # calculate difference betwen old (\"hat\") and \"new\" estimates\n","    alphaDiff = 0.5 * abs((alpha_new - alpha_hat) / (alpha_new + alpha_hat))\n","    betaDiff = 0.5 * abs((beta_new - beta_hat) / (beta_new + beta_hat))\n","    xiDiff = 0.5 * abs((xi_new - xi_hat) / (xi_new + xi_hat))\n","\n","    totalDiff = alphaDiff + betaDiff + xiDiff\n","\n","    # update old (\"hat\") estimates with \"new\" estimates\n","    alpha_hat = alpha_new\n","    beta_hat = beta_new\n","    xi_hat = xi_new\n","\n","    # Step 3: convergence test\n","    # exit loop if total difference between past and current parameter estimates is within tolerance\n","    if (totalDiff < tolerance) break\n","  }\n","  # return parameter estimates\n","  return(list(alpha=alpha_hat, beta=beta_hat, xi=xi_hat))\n","}"],"metadata":{"id":"XcEK51vcFFY5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now we can fit a P3 distribution to the log(data), or -log(data) if the skewness is negative."],"metadata":{"id":"IFoNEbsZM4vU"}},{"cell_type":"code","source":["library(fitdistrplus)\n","\n","if(e1071::skewness(log(data$X1.Day.Flow), type=2)<0){\n","  LP3.params = gamma3MOM(-log(data$X1.Day.Flow))\n","  LP3.fit.mom = fitdist(-log(data$X1.Day.Flow), \"gamma3\",\n","          order=c(1,2,3),\n","          memp=memp.centered,\n","          start=list(shape=LP3.params$alpha,\n","                     scale=1/LP3.params$beta,\n","                     thres=LP3.params$xi),\n","          lower=c(-Inf,0,-Inf),\n","          upper=c(Inf,Inf,Inf),\n","          method=\"mme\")\n","  q100 = exp(-qgamma3(1/100, LP3.fit.mom$estimate[1],\n","                     LP3.fit.mom$estimate[2], LP3.fit.mom$estimate[3]))\n","  q500 = exp(-qgamma3(1/500, LP3.fit.mom$estimate[1],\n","                     LP3.fit.mom$estimate[2], LP3.fit.mom$estimate[3]))\n","} else {\n","  LP3.params = gamma3MOM(log(data$X1.Day.Flow))\n","  LP3.fit.mom = fitdist(log(data$X1.Day.Flow), \"gamma3\",\n","          order=c(1,2,3),\n","          memp=memp.centered,\n","          start=list(shape=LP3.params$alpha,\n","                     scale=1/LP3.params$beta,\n","                     thres=LP3.params$xi),\n","          method=\"mme\")\n","  q100 = exp(qgamma3(1-1/100, LP3.fit.mom$estimate[1],\n","                     LP3.fit.mom$estimate[2], LP3.fit.mom$estimate[3]))\n","  q500 = exp(qgamma3(1-1/500, LP3.fit.mom$estimate[1],\n","                     LP3.fit.mom$estimate[2], LP3.fit.mom$estimate[3]))\n","}\n","\n","print(LP3.params)\n","print(paste(\"100-yr flood: \",q100))\n","print(paste(\"500-yr flood: \",q500))\n","plot(LP3.fit.mom)"],"metadata":{"id":"XkPVJMxIISqf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's investigate the fit more closely using a logit transformation of the annual exceedance probability - this will stretch out the fit in the tails so we can see it more closely."],"metadata":{"id":"7p8wsfkYtOkR"}},{"cell_type":"code","source":["library(ggplot2)\n","library(scales)\n","\n","# make a data frame with the annual exceedance probability (AEP) based on plotting positions\n","# the corresponding observations, and the fitted values at those percentiles\n","n = length(data$X1.Day.Flow)\n","p=c(seq(1,n,1))/(n+1)\n","if(e1071::skewness(log(data$X1.Day.Flow), type=2)<0){\n","  fitted = exp(-qgamma3(1-p, LP3.fit.mom$estimate[1], LP3.fit.mom$estimate[2], LP3.fit.mom$estimate[3]))\n","} else{\n","  fitted = exp(qgamma3(p, LP3.fit.mom$estimate[1], LP3.fit.mom$estimate[2], LP3.fit.mom$estimate[3]))\n","}\n","data_probplot = data.frame(obs=sort(data$X1.Day.Flow), AEP=100*(1-p), fitted=fitted)\n","\n","# create a reversed, logit transformation for the x axis\n","logit = trans_new(\"logit perc\",\n","              transform = function(x) -qlogis(x/100),\n","              inverse = function(x) 100*plogis(-x))\n","\n","# plot the fitted distribution in blue with the observations in black\n","ggplot(data_probplot, aes(x=AEP, y=fitted)) + geom_line(size=2, color=\"blue\") +\n","  geom_point(aes(x=AEP,y=obs),size=3) +\n","  scale_y_continuous(trans='log10') +\n","  coord_trans(x=logit) +\n","  theme(axis.text=element_text(size=16),\n","  axis.title=element_text(size=18))"],"metadata":{"id":"t7mrjYakeDyo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["You can see the upper tail is distribution fit is below the observations, which is concerning. This could be due to the influence of low outliers.  \n","\n","Let's see how many are identified by the Multiple Grubbs Beck Test."],"metadata":{"id":"zGAXsQ_MLyu0"}},{"cell_type":"code","source":["library(MGBT)\n","?MGBT::MGBT"],"metadata":{"id":"nbClt-oVNlSd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mgbt <- MGBT::MGBT(data$X1.Day.Flow) # compute the MGB test\n","mgbt"],"metadata":{"id":"XKj_rRswPjU5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["$klow$ is 6 corresponding to 6 PILFs. $LOThresh$ is 45, the flow of the 7th lowest observation, so everything below that (the 6th and below) is censored. Let's show these outliers in the figure above."],"metadata":{"id":"JjjEfu-_PMoe"}},{"cell_type":"code","source":["data_probplot$Outliers = c(rep(\"No\",length(data_probplot$obs)))\n","data_probplot$Outliers[which(data_probplot$obs < mgbt$LOThres)] = \"Yes\"\n","\n","# plot the fitted distribution in blue with the observations in black\n","ggplot(data_probplot, aes(x=AEP, y=fitted)) + geom_line(size=2, color=\"black\") +\n","  geom_point(aes(x=AEP,y=obs,color=Outliers),size=3) +\n","  scale_y_continuous(trans='log10') +\n","  coord_trans(x=logit) +\n","  scale_color_brewer(palette=\"Dark2\") +\n","  theme(axis.text=element_text(size=16),\n","  axis.title=element_text(size=18),\n","  legend.text=element_text(size=16),\n","  legend.title=element_text(size=18))"],"metadata":{"id":"XzTb396y2TP6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's re-fit the LP3 distribution using EMA with this threshold, then estimate the 100-yr and 500-yr floods from the updated estimate."],"metadata":{"id":"JZJFi77a2TcX"}},{"cell_type":"code","source":["# treat the 3 censored observations as a 3-year historical period with 0 exceedances of the threshold\n","# and all other observations as an n-3 year systematic record to fit with EMA\n","x = log(data$X1.Day.Flow[which(data$X1.Day.Flow >= mgbt$LOThresh)])\n","s = length(x)\n","y = log(data$X1.Day.Flow[which(data$X1.Day.Flow < mgbt$LOThresh)])\n","h = length(y)\n","T = log(mgbt$LOThresh)\n","tolerance = 0.0001\n","maxiter = 99\n","\n","# get initial LP3 parameter estimates from whole record without censoring\n","params0 = LP3.params\n","if(e1071::skewness(log(data$X1.Day.Flow),type=2)<0){\n","  params0$beta = -params0$beta\n","  params0$xi = -params0$xi\n","}\n","\n","# fit distribution with EMA\n","LP3.params.EMA = EMA_gamma3(x, y, s, h, T, params0, tolerance, maxiter)\n","print(LP3.params.EMA)\n","\n","if (LP3.params.EMA$beta<0){\n","  q100.EMA = exp(-qgamma3(1/100, LP3.params.EMA$alpha,\n","                            -1/LP3.params.EMA$beta, LP3.params.EMA$xi))\n","  q500.EMA = exp(-qgamma3(1/500, LP3.params.EMA$alpha,\n","                            -1/LP3.params.EMA$beta, LP3.params.EMA$xi))\n","} else {\n","  q100.EMA = exp(qgamma3(1-1/100, LP3.params.EMA$alpha,\n","                            1/LP3.params.EMA$beta, LP3.params.EMA$xi))\n","  q500.EMA = exp(qgamma3(1-1/500, LP3.params.EMA$alpha,\n","                            1/LP3.params.EMA$beta, LP3.params.EMA$xi))\n","}\n","print(paste(\"100-yr flood: \",q100.EMA))\n","print(paste(\"500-yr flood: \",q500.EMA))"],"metadata":{"id":"KGieF9JESU6-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The 100-yr flood estimate increased from 4,052 to 6,349 and the 500-yr flood estimate increased from 4,912 to 10,503! How is the fit now?"],"metadata":{"id":"vk6q7yuiTUsK"}},{"cell_type":"code","source":["# add new fitted values to previous data_probplot data frame and add a line for them in red to the plot\n","if(LP3.params.EMA$beta<0){\n","  MGBT_fitted = exp(-qgamma3(1-p, LP3.params.EMA$alpha, -1/LP3.params.EMA$beta, LP3.params.EMA$xi))\n","} else{\n","  MGBT_fitted = exp(qgamma3(p, LP3.params.EMA$alpha, 1/LP3.params.EMA$beta, LP3.params.EMA$xi))\n","}\n","data_probplot$MGBT_fit = MGBT_fitted\n","\n","# plot the original fitted distribution in blue,\n","# the MGBT fitted distribution in red\n","# and the observations in black\n","ggplot(data_probplot, aes(x=AEP, y=fitted, color=\"All Data\")) + geom_line(size=2) +\n","  geom_line(aes(x=AEP, y=MGBT_fitted, color=\"No PILFs\"), size=2) +\n","  geom_point(aes(x=AEP,y=obs,color=Outliers),size=3) +\n","  scale_y_continuous(trans='log10') +\n","  coord_trans(x=logit) +\n","  scale_color_brewer(palette=\"Dark2\") +\n","  theme(axis.text=element_text(size=16),\n","  axis.title=element_text(size=18),\n","  legend.text=element_text(size=16),\n","  legend.title=element_text(size=18)) +\n","  scale_color_manual(name=\"\", values=c(\"All Data\"=\"black\",\"No PILFs\"=\"#7570b3\", \"No\"=\"#1b9e77\", \"Yes\"=\"#d95f02\"),\n","                      labels=c(\"Uncensored Fit\",\"Retained Data\",\"Censored Fit\",\"Censored Data\"))"],"metadata":{"id":"uEsKlXbJsZNi"},"execution_count":null,"outputs":[]}]}