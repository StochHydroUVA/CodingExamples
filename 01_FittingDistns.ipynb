{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNVPQMSzF4iBPj4iS+StD1S"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Example code for fitting Normal and Log-Normal Distributions using MLE and MOM\n","\n","First, import the following libraries\n","- pandas: to read in data  \n","- numpy: for basic mathematical functions over arrays  \n","- scipy.stats: for distribution-fitting functions\n","- matplotlib.pyplot: for plotting distribution fits\n","- google.colab.drive: for accessing data on Google Drive"],"metadata":{"id":"36i0XAxd7fSw"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"2LrOAkCD6_-w"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import scipy.stats as ss\n","import matplotlib.pyplot as plt\n","from google.colab import drive"]},{"cell_type":"markdown","source":["Load data of annual maxima at Azibe Soltane on the Sebou River in Morocco"],"metadata":{"id":"8JjNDRUu8l5f"}},{"cell_type":"code","source":["# allow access to google drive\n","drive.mount('/content/drive')\n","\n","maxQ = pd.read_csv(\"drive/MyDrive/Colab Notebooks/CE6280/Data/Problem6.17.csv\")\n","maxQ.head()"],"metadata":{"id":"HI159LJ28o2Q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Visualize the data in a histogram"],"metadata":{"id":"tJ2nwDim9cuh"}},{"cell_type":"code","source":["plt.hist(maxQ[\"Flow\"], density=True)\n","plt.xlabel(\"Flow (cms)\")\n","plt.ylabel(\"Density\")\n","plt.title(\"PDF of Annual Maxima of Sebou River at Azibe Soltane\")"],"metadata":{"id":"q8TVGPoG9eS_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Calculate the mean, variance/standard deviation, and skewness using default numpy functions"],"metadata":{"id":"NHSAYu-y-Mx2"}},{"cell_type":"code","source":["mu = np.mean(maxQ[\"Flow\"])\n","sigmaSq = np.var(maxQ[\"Flow\"])\n","sigma = np.std(maxQ[\"Flow\"])\n","gamma = ss.skew(maxQ[\"Flow\"])\n","\n","# what are they?\n","print(\"mean %0.2f\" % mu)\n","print(\"variance: %0.2f\" % sigmaSq)\n","print(\"std. dev.: %0.2f\" % sigma)\n","print(\"skewness: %0.2f\" % gamma)"],"metadata":{"id":"3XfFVfCt-QDl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["With the exception of the mean, these estimates are actually biased. How do they compare with the unbiased estimates?"],"metadata":{"id":"AeWSbD-H_Crg"}},{"cell_type":"code","source":["# using unbiased estimators (formulas given in lecture)\n","sigmaSq_unbiased = np.var(maxQ[\"Flow\"], ddof=1)\n","sigma_unbiased = np.std(maxQ[\"Flow\"], ddof=1)\n","gamma_unbiased = ss.skew(maxQ[\"Flow\"], bias=False)\n","\n","# compare the estimators\n","print(\"unbiased variance: %0.2f\" % sigmaSq_unbiased)\n","print(\"unbiased std. dev.: %0.2f\" % sigma_unbiased)\n","print(\"unbiased skewness: %0.2f\" % gamma_unbiased)\n","\n","# how different are they?\n","print(\"percent difference in biased vs. unbiased variance: %0.1f\" % np.abs((sigmaSq - sigmaSq_unbiased)*100 / (0.5*(sigmaSq + sigmaSq_unbiased))))\n","print(\"percent difference in biased vs. unbiased std. dev.: %0.1f\" % np.abs((sigma - sigma_unbiased)*100 / (0.5*(sigma + sigma_unbiased))))\n","print(\"percent difference in biased vs. unbiased skewness: %0.1f\" % np.abs((gamma - gamma_unbiased)*100 / (0.5*(gamma + gamma_unbiased))))\n"],"metadata":{"id":"NiWWo2CF_F5U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Fit a normal distribution to the data using MLE. This is the approach in scipy.stats.fit, which returns the location and scale parameters of the distribution."],"metadata":{"id":"OWPXXK41AjBB"}},{"cell_type":"code","source":["loc, scale = ss.norm.fit(maxQ[\"Flow\"])\n","\n","print(\"loc: %0.2f\" % loc)\n","print(\"scale: %0.2f\" % scale)"],"metadata":{"id":"54vm-fIAAnSL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This prints the location and scale parameters, which in this case are $\\mu$ and $\\sigma$. You can see from the code above, this is the same as the mean and BIASED variance. Let's rename this mu_fit and sigma_fit, the fitted values of $\\mu$ and $\\sigma$."],"metadata":{"id":"AHKfp0y4A8rU"}},{"cell_type":"code","source":["mu_fit = loc\n","sigma_fit = scale"],"metadata":{"id":"5lFsFlKGB7jp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["How does the fit look? Let's compare the fitted PDF with the histogram of the data.  \n","ss.norm.pdf(x, loc, scale) calculates the value of a normal PDF, f(x), with parameters loc and scale at input values x"],"metadata":{"id":"Wv-T93YEB7IZ"}},{"cell_type":"code","source":["x = np.arange(0,4500,10)\n","f_x = ss.norm.pdf(x, mu_fit, sigma_fit)\n","\n","plt.hist(maxQ[\"Flow\"], density=True)\n","plt.plot(x,f_x)\n","plt.ylim([0,0.0015])\n","plt.xlim([0,4500])\n","plt.title('Normal MLE fit')\n","plt.xlabel('Flow (cms)')\n","plt.ylabel('Probability Density')"],"metadata":{"id":"JJoKv3NYBDkR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Clearly this is not a good fit! We need a skewed distribution. Let's use a log-normal.  \n","ss.lognorm.fit returns the shape, location and scale parameters of a 3-parameter log-normal distribution. You can fit a 2-parameter log-normal distribution by fixing the lower bound (location) parameter at 0 with floc=0.  \n","The parameter $\\mu$ of a LN distribution is the log of the scale parameter reported by scipy.stats. The parameter $\\sigma$ is the shape parameter."],"metadata":{"id":"vMoJyB2LClow"}},{"cell_type":"code","source":["# fit a log-normal distribution to the data\n","shape, loc, scale = ss.lognorm.fit(maxQ['Flow'], floc=0)\n","\n","# convert shape and scale to estimates of mu and sigma\n","mu_LN_MLE = np.log(scale)\n","sigma_LN_MLE = shape\n","\n","print('mu: %0.2f' % mu_LN_MLE)\n","print('sigma: %0.2f' % sigma_LN_MLE)"],"metadata":{"id":"9Fh6gr7ICovP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Compare these estimates with what we get from the formulas computed in class"],"metadata":{"id":"DNVuklCdEWqY"}},{"cell_type":"code","source":["# compute using equations from class for MLE\n","mu_LN_MLE_check = np.mean(np.log(maxQ[\"Flow\"]))\n","sigma_LN_MLE_check = np.sqrt( np.mean( (np.log(maxQ[\"Flow\"]) - mu_LN_MLE_check)**2 ) )\n","\n","# compare estimates\n","print(\"Python mu: %0.2f\" % mu_LN_MLE)\n","print(\"Class mu: %0.2f\" % mu_LN_MLE_check)\n","print(\"Python sigma: %0.2f\" % sigma_LN_MLE)\n","print(\"Class sigma: %0.2f\" % sigma_LN_MLE_check)"],"metadata":{"id":"typbauXREB3_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["How does this fit look?"],"metadata":{"id":"PX3dNGA4Etk9"}},{"cell_type":"code","source":["x = np.arange(0,4500,10)\n","f_x = ss.lognorm.pdf(x, shape, loc, scale)\n","\n","plt.hist(maxQ[\"Flow\"], density=True)\n","plt.plot(x,f_x)\n","plt.ylim([0,0.0015])\n","plt.xlim([0,4500])\n","plt.title('2-parameter log-normal MLE fit')\n","plt.xlabel('Flow (cms)')\n","plt.ylabel('Probability Density')"],"metadata":{"id":"PCquTEZzEu73"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Much better! What is our estimate of the 100-year flood from this fit? The 100-year flood occurs on average 1/100 years. 1/100 = 0.01, so there is a 1\\% chance of it being exceeded each year. That means it is the 0.99 quantile of the distribution.  \n","We can estimates quantiles of distributions in scipy with ppf, the \"point percentile function\"."],"metadata":{"id":"QKnwmFf2E4Mj"}},{"cell_type":"code","source":["q0_99_LN_MLE = ss.lognorm.ppf(0.99, shape, loc, scale)\n","print(\"100-year flood estimate: %0.0f cfs\" % q0_99_LN_MLE)"],"metadata":{"id":"RFbCgZmgFQOc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["What if we wanted to fit the Log-normal distribution using MOM? scipy.stats does not do this, so we need to write our own code for it. Use the formulas we computed in class."],"metadata":{"id":"lvPCL4_gFlIs"}},{"cell_type":"code","source":["# compute using equations from class for MOM\n","sigma_LN_MOM = np.sqrt( np.log( 1 + np.var(maxQ[\"Flow\"], ddof=1) / (np.mean(maxQ[\"Flow\"])**2) ) )\n","mu_LN_MOM = np.log(np.mean(maxQ[\"Flow\"])) - 0.5*sigma_LN_MOM**2\n","q0_99_LN_MOM = ss.lognorm.ppf(0.99, sigma_LN_MOM, 0, np.exp(mu_LN_MOM))\n","\n","print(\"MOM mu: %0.2f\" % mu_LN_MOM)\n","print(\"MOM sigma: %0.2f\" % sigma_LN_MOM)\n","print(\"100-year flood estimate: %0.0f cfs\" % q0_99_LN_MOM)\n","\n","x = np.arange(0,4500,10)\n","f_x = ss.lognorm.pdf(x, sigma_LN_MOM, 0, np.exp(mu_LN_MOM))\n","\n","plt.hist(maxQ[\"Flow\"], density=True)\n","plt.plot(x,f_x)\n","plt.ylim([0,0.0015])\n","plt.xlim([0,4500])\n","plt.title('2-parameter log-normal MLE fit')\n","plt.xlabel('Flow (cms)')\n","plt.ylabel('Probability Density')"],"metadata":{"id":"6PuYWiXYFktb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Small differences in the parameter estimates can result in big differences in the estimates of extremes events! Clearly uncertainty will be important to quantify here.  \n","What if we used the 3-parameter log-normal distribution? First, let's use MLE."],"metadata":{"id":"fwnxnVEdIxl6"}},{"cell_type":"code","source":["# fit a log-normal distribution to the data\n","shape, loc, scale = ss.lognorm.fit(maxQ['Flow'])\n","q0_99_LN3_MLE = ss.lognorm.ppf(0.99, shape, loc, scale)\n","\n","# convert shape and scale to estimates of mu and sigma\n","mu_LN3_MLE = np.log(scale)\n","sigma_LN3_MLE = shape\n","tau_LN3_MLE = loc\n","\n","print('tau: %0.2f' % tau_LN3_MLE)\n","print('mu: %0.2f' % mu_LN3_MLE)\n","print('sigma: %0.2f' % sigma_LN3_MLE)\n","print(\"100-year flood estimate: %0.0f cfs\" % q0_99_LN3_MLE)\n","\n","x = np.arange(0,4500,10)\n","f_x = ss.lognorm.pdf(x, shape, loc, scale)\n","\n","plt.hist(maxQ[\"Flow\"], density=True)\n","plt.plot(x,f_x)\n","plt.ylim([0,0.002])\n","plt.xlim([0,4500])\n","plt.title('3-parameter log-normal MLE fit')\n","plt.xlabel('Flow (cms)')\n","plt.ylabel('Probability Density')"],"metadata":{"id":"mhzdB0O3GVUQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["And for LN3 using MOM. For this, we'll need to use root-finding to find the value of $\\sigma$ that makes the difference between the theoretical and empirical moments 0. This parameter is bounded below by 0 and above by std(log(x)). However, it is undefined at 0, so we will pass a lower bound of 0.01."],"metadata":{"id":"m9cRGKdfHhfW"}},{"cell_type":"code","source":["from scipy.optimize import brentq as root\n","\n","sigma_LN3_MOM = root(lambda x: (np.exp(3*x**2)-3*np.exp(x**2)+2) / (np.exp(x**2)-1)**(3/2) - ss.skew(maxQ[\"Flow\"],bias=False),\n","             0.01, np.std(np.log(maxQ[\"Flow\"]),ddof=1))\n","mu_LN3_MOM = 0.5 * (np.log(np.var(maxQ[\"Flow\"],ddof=1) / (np.exp(sigma_LN3_MOM**2)-1)) - sigma_LN3_MOM**2)\n","tau_LN3_MOM = np.mean(maxQ[\"Flow\"]) - np.exp(mu_LN3_MOM + 0.5*sigma_LN3_MOM**2)\n","q0_99_LN3_MOM = ss.lognorm.ppf(0.99, sigma_LN3_MOM, tau_LN3_MOM, np.exp(mu_LN3_MOM))\n","\n","print('tau: %0.2f' % tau_LN3_MOM)\n","print('mu: %0.2f' % mu_LN3_MOM)\n","print('sigma: %0.2f' % sigma_LN3_MOM)\n","print(\"100-year flood estimate: %0.0f cfs\" % q0_99_LN3_MOM)\n","\n","x = np.arange(0,4500,10)\n","f_x = ss.lognorm.pdf(x, sigma_LN3_MOM, tau_LN3_MOM, np.exp(mu_LN3_MOM))\n","\n","plt.hist(maxQ[\"Flow\"], density=True)\n","plt.plot(x,f_x)\n","plt.ylim([0,0.002])\n","plt.xlim([0,4500])\n","plt.title('3-parameter log-normal MOM fit')\n","plt.xlabel('Flow (cms)')\n","plt.ylabel('Probability Density')"],"metadata":{"id":"zMu3d8cgHkB9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can write a function to fit LN2 or LN3 using MOM or MLE depending on the input arguments."],"metadata":{"id":"gaXBPVLYGNd8"}},{"cell_type":"code","source":["def findMoments(data):\n","  xbar = np.mean(data)\n","  var = np.var(data, ddof=1)\n","  skew = ss.skew(data, bias=False)\n","  kurtosis = ss.kurtosis(data, bias=False)\n","\n","  return xbar, var, skew, kurtosis\n","\n","def fitLN(data, method, npars):\n","  assert method == 'MLE' or method == 'MOM',\"method must = 'MLE' or 'MOM'\"\n","  assert npars == 2 or npars == 3,\"npars must = 2 or 3\"\n","\n","  xbar, var, skew, kurtosis = findMoments(data)\n","  if method == 'MLE':\n","    if npars == 2:\n","      shape, loc, scale = ss.lognorm.fit(data, floc=0)\n","    elif npars == 3:\n","      shape, loc, scale = ss.lognorm.fit(data)\n","\n","    mu = np.log(scale)\n","    sigma = shape\n","    tau = loc\n","  elif method == 'MOM':\n","    if npars == 2:\n","      sigma = np.sqrt(np.log(1+var/xbar**2))\n","      mu = np.log(xbar) - 0.5*sigma**2\n","      tau = 0\n","    elif npars == 3:\n","      sigma = root(lambda x: (np.exp(3*x**2)-3*np.exp(x**2)+2) / (np.exp(x**2)-1)**(3/2) - skew,\n","                   0.01, np.std(np.log(data),ddof=1))\n","      mu = 0.5 * (np.log(var / (np.exp(sigma**2)-1)) - sigma**2)\n","      tau = xbar - np.exp(mu + 0.5*sigma**2)\n","\n","  return sigma, tau, mu\n","\n","def findLNreturnPd(sigma, tau, mu, T):\n","  q_T = ss.lognorm.ppf(1-1/T, sigma, tau, np.exp(mu))\n","\n","  return q_T"],"metadata":{"id":"839OGhGNI5Zg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now run it and report the parameters"],"metadata":{"id":"XA-cCYbOJtAG"}},{"cell_type":"code","source":["sigma_LN2_MOM, tau_LN2_MOM, mu_LN2_MOM = fitLN(maxQ[\"Flow\"], \"MOM\", 2)\n","q0_99_LN2_MOM = findLNreturnPd(sigma_LN2_MOM, tau_LN2_MOM, mu_LN2_MOM, 100)\n","\n","sigma_LN2_MLE, tau_LN2_MLE, mu_LN2_MLE = fitLN(maxQ[\"Flow\"], \"MLE\", 2)\n","q0_99_LN2_MLE = findLNreturnPd(sigma_LN2_MLE, tau_LN2_MLE, mu_LN2_MLE, 100)\n","\n","sigma_LN3_MOM, tau_LN3_MOM, mu_LN3_MOM = fitLN(maxQ[\"Flow\"], \"MOM\", 3)\n","q0_99_LN3_MOM = findLNreturnPd(sigma_LN3_MOM, tau_LN3_MOM, mu_LN3_MOM, 100)\n","\n","sigma_LN3_MLE, tau_LN3_MLE, mu_LN3_MLE = fitLN(maxQ[\"Flow\"], \"MLE\", 3)\n","q0_99_LN3_MLE = findLNreturnPd(sigma_LN3_MLE, tau_LN3_MLE, mu_LN3_MLE, 100)\n","\n","print(\"LN2 MOM mu: %0.2f\" % mu_LN2_MOM)\n","print(\"LN2 MOM sigma: %0.2f\" % sigma_LN2_MOM)\n","print(\"LN2 MOM tau: %0.2f\" % tau_LN2_MOM)\n","print(\"LN2 MOM 100-yr flood: %0.0f\" % q0_99_LN2_MOM)\n","\n","print(\"LN2 MLE mu: %0.2f\" % mu_LN2_MLE)\n","print(\"LN2 MLE sigma: %0.2f\" % sigma_LN2_MLE)\n","print(\"LN2 MLE tau: %0.2f\" % tau_LN2_MLE)\n","print(\"LN2 MLE 100-yr flood: %0.0f\" % q0_99_LN2_MLE)\n","\n","print(\"LN3 MOM mu: %0.2f\" % mu_LN3_MOM)\n","print(\"LN3 MOM sigma: %0.2f\" % sigma_LN3_MOM)\n","print(\"LN3 MOM tau: %0.2f\" % tau_LN3_MOM)\n","print(\"LN3 MOM 100-yr flood: %0.0f\" % q0_99_LN3_MOM)\n","\n","print(\"LN3 MLE mu: %0.2f\" % mu_LN3_MLE)\n","print(\"LN3 MLE sigma: %0.2f\" % sigma_LN3_MLE)\n","print(\"LN3 MLE tau: %0.2f\" % tau_LN3_MLE)\n","print(\"LN3 MLE 100-yr flood: %0.0f\" % q0_99_LN3_MLE)"],"metadata":{"id":"JQvpmBCoJu1x"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We could even make these methods part of a LogNormal class, which could be a subclass of the Distribution class."],"metadata":{"id":"hMua1bSSRMQA"}},{"cell_type":"code","source":["class Distribution:\n","  def __init__(self):\n","    self.xbar = None\n","    self.var = None\n","    self.skew = None\n","    self.kurtosis = None\n","\n","  def findMoments(self, data):\n","    self.xbar = np.mean(data)\n","    self.var = np.var(data, ddof=1)\n","    self.skew = ss.skew(data, bias=False)\n","    self.kurtosis = ss.kurtosis(data, bias=False)\n","\n","class LogNormal(Distribution):\n","  def __init__(self):\n","    super().__init__()\n","    self.mu = None\n","    self.sigma = None\n","    self.tau = None\n","\n","  def fit(self, data, method, npars):\n","    assert method == 'MLE' or method == 'MOM',\"method must = 'MLE' or 'MOM'\"\n","    assert npars == 2 or npars == 3,\"npars must = 2 or 3\"\n","\n","    self.findMoments(data)\n","    if method == 'MLE':\n","      if npars == 2:\n","        shape, loc, scale = ss.lognorm.fit(data, floc=0)\n","      elif npars == 3:\n","        shape, loc, scale = ss.lognorm.fit(data)\n","\n","      self.mu = np.log(scale)\n","      self.sigma = shape\n","      self.tau = loc\n","    elif method == 'MOM':\n","      if npars == 2:\n","        self.sigma = np.sqrt(np.log(1+self.var/self.xbar**2))\n","        self.mu = np.log(self.xbar) - 0.5*self.sigma**2\n","        self.tau = 0\n","      elif npars == 3:\n","        self.sigma = root(lambda x: (np.exp(3*x**2)-3*np.exp(x**2)+2) / (np.exp(x**2)-1)**(3/2) - self.skew,\n","                   0.01, np.std(np.log(data),ddof=1))\n","        self.mu = 0.5 * (np.log(self.var / (np.exp(self.sigma**2)-1)) - self.sigma**2)\n","        self.tau = self.xbar - np.exp(self.mu + 0.5*self.sigma**2)\n","\n","  def findReturnPd(self, T):\n","    q_T = ss.lognorm.ppf(1-1/T, self.sigma, self.tau, np.exp(self.mu))\n","    return q_T\n","\n","  def plotHistPDF(self, data, min, max):\n","    x = np.arange(min, max,(max-min)/100)\n","    f_x = ss.lognorm.pdf(x, self.sigma, self.tau, np.exp(self.mu))\n","\n","    plt.hist(data, density=True)\n","    plt.plot(x,f_x)\n","    plt.xlim([min, max])\n","    plt.title('Log-normal fit')\n","    plt.xlabel('Flow')\n","    plt.ylabel('Probability Density')"],"metadata":{"id":"F4SpjwJaRL9r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now run the code again using these classes."],"metadata":{"id":"JzxrROQJUr-V"}},{"cell_type":"code","source":["LN2_MOM_Fit = LogNormal()\n","LN2_MOM_Fit.fit(maxQ[\"Flow\"],\"MOM\", 2)\n","LN2_MOM_q100 = LN2_MOM_Fit.findReturnPd(100)\n","LN2_MOM_Fit.plotHistPDF(maxQ[\"Flow\"], 0, 4500)\n","\n","LN2_MLE_Fit = LogNormal()\n","LN2_MLE_Fit.fit(maxQ[\"Flow\"],\"MLE\", 2)\n","LN2_MLE_q100 = LN2_MLE_Fit.findReturnPd(100)\n","LN2_MLE_Fit.plotHistPDF(maxQ[\"Flow\"], 0, 4500)\n","\n","LN3_MOM_Fit = LogNormal()\n","LN3_MOM_Fit.fit(maxQ[\"Flow\"],\"MOM\", 3)\n","LN3_MOM_q100 = LN3_MOM_Fit.findReturnPd(100)\n","LN3_MOM_Fit.plotHistPDF(maxQ[\"Flow\"], 0, 4500)\n","\n","LN3_MLE_Fit = LogNormal()\n","LN3_MLE_Fit.fit(maxQ[\"Flow\"],\"MLE\", 3)\n","LN3_MLE_q100 = LN3_MLE_Fit.findReturnPd(100)\n","LN3_MLE_Fit.plotHistPDF(maxQ[\"Flow\"], 0, 4500)\n","\n","print(\"LN2 MOM mu: %0.2f\" % LN2_MOM_Fit.mu)\n","print(\"LN2 MOM sigma: %0.2f\" % LN2_MOM_Fit.sigma)\n","print(\"LN2 MOM tau: %0.2f\" % LN2_MOM_Fit.tau)\n","print(\"LN2 MOM 100-yr flood: %0.0f\" % LN2_MOM_q100)\n","\n","print(\"LN2 MLE mu: %0.2f\" % LN2_MLE_Fit.mu)\n","print(\"LN2 MLE sigma: %0.2f\" % LN2_MLE_Fit.sigma)\n","print(\"LN2 MLE tau: %0.2f\" % LN2_MLE_Fit.tau)\n","print(\"LN2 MLE 100-yr flood: %0.0f\" % LN2_MLE_q100)\n","\n","print(\"LN3 MOM mu: %0.2f\" % LN3_MOM_Fit.mu)\n","print(\"LN3 MOM sigma: %0.2f\" % LN3_MOM_Fit.sigma)\n","print(\"LN3 MOM tau: %0.2f\" % LN3_MOM_Fit.tau)\n","print(\"LN3 MOM 100-yr flood: %0.0f\" % LN3_MOM_q100)\n","\n","print(\"LN3 MLE mu: %0.2f\" % LN3_MLE_Fit.mu)\n","print(\"LN3 MLE sigma: %0.2f\" % LN3_MLE_Fit.sigma)\n","print(\"LN3 MLE tau: %0.2f\" % LN3_MLE_Fit.tau)\n","print(\"LN3 MLE 100-yr flood: %0.0f\" % LN3_MLE_q100)"],"metadata":{"id":"lq-u9zAVUrdq"},"execution_count":null,"outputs":[]}]}